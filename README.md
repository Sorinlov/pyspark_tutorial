# pyspark_tutorial

## How spark works

* RDD
* basic API deal with data
* basic work nodes

* Actions
* show
* count
* collect
* save
  ...
* Transformation (L)
* select
* distinct
* groupby
* sum and other aggregations
* orderby
* orderby
* filter
* limit
  ...
* Lazy evaluation 
* Transformations are only triggered when there is an action
  
* so more L, less actions, more faster
  
## Types of Text Data

* schema-never data (Unstructed data)
* schema-later data (semistructured data)
  * give schema after we read it
* schema-first data (structed data)
